{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9731fa6e-84cf-444e-99d6-050c792f5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3669447c-d23d-48c2-8aec-07887848b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rruba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rruba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5743e-5c86-4c5a-9760-9b57cd7e9251",
   "metadata": {},
   "source": [
    "### Step 0: Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78c2c0d2-a77b-474c-bc0c-d7dc61057ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         source_text\n",
      "0  sinif , havuz ve acik deniz calismalariyla , t...\n",
      "1  bu standart , sualtinda kendini rahat hisseden...\n",
      "2  yapilan arastirmalar , ogrencilerin mevcut dal...\n",
      "3  pdic ogrencilerinde , psikolojik egitim ve yet...\n",
      "4  pdic egitiminin sagladigi guven ve rahatlik , ...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'train_fixed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe15341-0a1a-455c-8da7-fcb6dbcf07dc",
   "metadata": {},
   "source": [
    "### Step 1: Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fa9026-58ee-4c82-955e-69890ea484ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Standardize punctuation (example shown for a common case)\n",
    "    text = re.sub(r'[\\u201C\\u201D]', '\"', text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042f1488-75a2-4b76-8293-1e762df87c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['normalized_text'] = data['Sentence'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb63d7-2933-4959-921f-969e58562e3c",
   "metadata": {},
   "source": [
    "### Step 2: Removal of HTML Tags and Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aaf2e48-fdea-4cc4-8915-2fdca54e81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    soup = re.sub(r'[\\?\\)\\(\\:\\%\\»\\°\\|\\,\\.\\!]', '', soup)\n",
    "    soup = re.sub(r'[\\/\\-\\;]', ' ', soup)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c48f6d-7850-4651-a739-6650a704cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rruba\\AppData\\Local\\Temp\\ipykernel_19672\\3790859054.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "data['clean_text'] = data['normalized_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b11d8-1354-4453-ba91-f99eeb66328e",
   "metadata": {},
   "source": [
    "### Step 3: Numerical, Date, and Time Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74d2cc8-c611-4d95-8007-9b1926af34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    \n",
    "    text = re.sub(r'\\d{1,2}:\\d{2}', \"TIME\", text) \n",
    "    text = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', \"DATE\", text)\n",
    "    text = re.sub(r'\\d+', \"NUMBER\", text) \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7983d4fa-ef0c-485c-a727-ae4ddb8ed9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['standardized_text'] = data['clean_text'].apply(standardize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d728f-233d-46cc-aaa6-89e2cb0ea567",
   "metadata": {},
   "source": [
    "### Step 4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d123974d-22c4-4e67-81f3-a63d5875c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text, language='turkish')\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b047321a-2ba9-40fb-9a38-494df2399aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['standardized_text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa42fc-6b61-465a-bb82-7f0a5176286c",
   "metadata": {},
   "source": [
    "### Step 5: Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4958bd-57e9-45a7-b4ef-cdab1ec777fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('turkish'))\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "data['filtered_tokens'] = data['tokens'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccc7f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tokenize_text(text):\n",
    "    char_tokens = list(text)\n",
    "    return char_tokens\n",
    "\n",
    "data['char_tokens'] = data['standardized_text'].apply(char_tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddb2fe64-fdd5-438f-a2a2-15fcd6e71758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./data/cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_venv",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
