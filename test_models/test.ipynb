{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiacriticModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(DiacriticModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim * 2, num_layers, batch_first=True)  # *2 for bidirectional\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        encoder_output, encoder_hidden = self.encoder(embedded, hidden)\n",
    "        decoder_hidden = self.transform_hidden(encoder_hidden)\n",
    "        output, hidden = self.decoder(embedded, decoder_hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def transform_hidden(self, encoder_hidden):\n",
    "        # encoder_hidden contains both the hidden and cell states\n",
    "        # Each is a tuple (h_n, c_n) of shape [num_layers * num_directions, batch, hidden_size]\n",
    "        h_n, c_n = encoder_hidden\n",
    "        # Concatenate the hidden states for the forward and backward layers\n",
    "        h_n = torch.cat([h_n[0:h_n.size(0):2], h_n[1:h_n.size(0):2]], dim=2)\n",
    "        c_n = torch.cat([c_n[0:c_n.size(0):2], c_n[1:c_n.size(0):2]], dim=2)\n",
    "        return (h_n, c_n)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden state with zeros\n",
    "        # Note: We multiply layer_dim by 2 because of the bidirectional LSTM\n",
    "        return (torch.zeros(self.num_layers * 2, batch_size, self.hidden_dim).to(device),\n",
    "                torch.zeros(self.num_layers * 2, batch_size, self.hidden_dim).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load vocab\n",
    "with open('/content/drive/MyDrive/NLP/vocab.pickle', 'rb') as handle:\n",
    "    vocab = pickle.load(handle)\n",
    "\n",
    "# Load inv_vocab\n",
    "with open('/content/drive/MyDrive/NLP/inv_vocab.pickle', 'rb') as handle:\n",
    "    inv_vocab = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 111  \n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "model = DiacriticModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/NLP/model.pth', map_location=device))\n",
    "model.eval() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(sentence, vocab):\n",
    "    tokens = [vocab.get(char, vocab['<unk>']) for char in sentence]\n",
    "    return torch.tensor(tokens, dtype=torch.long, device=device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "test_data = pd.read_csv('/content/drive/MyDrive/NLP/test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence, vocab, inv_vocab):\n",
    "    input_tensor = prepare_input_data(sentence, vocab)\n",
    "    hidden = model.init_hidden(1)  # Assume batch size of 1 for individual predictions\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(input_tensor, hidden)\n",
    "    predicted_indices = output.argmax(dim=2).squeeze(0).tolist()\n",
    "    predicted_sentence = ''.join([inv_vocab[idx] for idx in predicted_indices])\n",
    "    return predicted_sentence\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    input_sentence = row['sentence']\n",
    "    pred_sentence = predict(model, input_sentence, vocab, inv_vocab)\n",
    "    predictions.append((row['id'], pred_sentence))\n",
    "\n",
    "# Convert results to a DataFrame for output\n",
    "predictions_df = pd.DataFrame(predictions, columns=['id', 'sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('/content/drive/MyDrive/NLP/predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
